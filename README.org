* Vision project


** Set up of TF object detection module.
   Please remember to put this in bin/activate after following the tensorflow model detection api's obj:
   
   https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md#add-libraries-to-pythonpath
   
   

   
   #+begin_src sh
     # INstallation instruction quick summary
     # For CPU
     pip install tensorflow
     # For GPU
     pip install tensorflow-gpu
   #+end_src


   
   The remaining libraries can be installed on Ubuntu 16.04 using via apt-get:

   #+begin_src sh
   sudo apt-get install protobuf-compiler python-pil python-lxml python-tk
   pip install --user Cython
   pip install --user contextlib2
   pip install --user jupyter
   pip install --user matplotlib
   
   Alternatively, users can install dependencies using pip:
   
   pip install --user Cython
   pip install --user contextlib2
   pip install --user pillow
   pip install --user lxml
   pip install --user jupyter
   pip install --user matplotlib
   #+end_src
   

   
   
   
   
   #+begin_src sh
     # FOr coco metrics
     git clone https://github.com/cocodataset/cocoapi.git
     cd cocoapi/PythonAPI
     make
     cp -r pycocotools <path_to_tensorflow>/models/research/

     # From tensorflow/models/research/
     protoc object_detection/protos/*.proto --python_out=.


     # From tensorflow/models/research/
     export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim

   #+end_src


   
** Experiments performed

   The data was prepared (made into tf-record shards of size 10)
   according to the guide.

   The following files were edited to allow for setting up the
   pipeline and the hyper-parameters for faster RCNN as well as what
   was to be done during training.

   config/faster_rcnn_resnet101_sdc.config -- has the configuration.
   config/sdc_label_map.pbtxt -- Has the class to label mapping.

   utils/visualize allows one to visualize tf-record shards.  Sharding
   was done to fit the training data onto the GPU.

   

   the run_sdc_train.sh script is used for running a tensorflow object
   detection.  This will have to be from the tensorflow's
   model/research folder.

   GCP will also have to be set up according to the installation
   guide.


** Code to run

   The following were done.

   
   #+begin_src sh
     python equalize.py
   #+end_src

   The path has to be set in the script to test or trainval.  This
   will perform adaptive equalization.  We found that doing adaptive
   equalization helps in improving the test results even when trained
   on the original train data.  We achieved the highest score we have
   from that though training we weren't able to train it for
   convergence for the images equalized for training as well.  


   Once that has been done, create tf record shards via the script.
   It splits the test data into multiple tf records for better memory
   bandwidth utilization and not having to move the entire data
   online.
   #+begin_src sh
     /home/akash/finals/vision/tf_preprocess_shards.py --data_dir=<train_datta> --output_path=<output_dir>
   #+end_src

   
   You'll also need the following files 
   * res/sdc_label_map.pbtxt
     * Describes the new labels and classes
   * config/faster_rcnn_resnet101_sdc.config
     * Describes the faster RCNN training parameters like learning
       rate, number of proposals etc.
     * We changed the last layer for training (the classification one)
     * We resize the inputs before we feed themn in.
       
   Once you have the tf-records, move them onto your GCP bucket and
   start the training via
   - run_sdc_train.sh (you should be in tensorflow's model/research
     folder.

   - Once training is complete, the following script will give what is
     needed.
     * to_frozen_graph.sh
     * You'll need to change paths as required.
       
       
   - The above step will create a frozen graph with which we can
     infer.  Again, from models/research, execute the following
     command to get the following.
     * final_output.csv
     * A pickled list of dictionaries containing information about the
       inference like bounding box classes, scores and boxes
       themselve.
     * Change the paths as required in the script.  It expects a
       frozen_graph.pb in the same foler as models/research
       
   #+begin_src sh
     infer_via_model.py
   #+end_src

   The output csv file requires some preprocessing (done via a
   regular text editor with regex replaces.  

   The pickled list goes as an input to the next task, which is used
   for finding the bounding boxes.
   
   

** Task 2

   Task 2 Instructions: Run the file Task2FinalCode.py with bbox_data
   in the code pointing to the correct location of the bounding box
   pkl file.  The code generates outputTask2.csv file in the current
   working directory.
